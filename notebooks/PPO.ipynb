{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flappy Bird - Proximal Policy Optimization\n",
    "\n",
    "In this notebook, we will implement a **Proximal Policy Optimization (PPO)** for the Flappy Bird game.\n",
    "\n",
    "\n",
    "\n",
    "## Index\n",
    "\n",
    "- [1. Initial Setup](#1.-Initial-Setup)\n",
    "- [2. Check the Gym environment](#2-check-the-gym-environment)\n",
    "- [3. Define custom functions](#3-define-custom-functions)\n",
    "- [4. Training the RL agent](#4-training-the-rl-agent)\n",
    "  - [4.1 Agent - Training](#4.1-agent-training)\n",
    "  - [4.1 Agent - Scores](#4.1-agent-scores)\n",
    "- [5. Save agent](#5-save-agent)\n",
    "- [6. Load agent](#6-load-agent)\n",
    "- [7. Test trained agent](#7-test-trained-agent)\n",
    "- [8. Conclusions](#8-conclusions)\n",
    "\n",
    "## References\n",
    "\n",
    "- [[1707.06347] Proximal Policy Optimization Algorithms](https://arxiv.org/abs/1707.06347)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Initial Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add project root directory to the path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "if str(Path(\".\").absolute().parent) not in sys.path:\n",
    "    sys.path.append(str(Path(\".\").absolute().parent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import flappy_bird_gym\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src.trainer import Trainer\n",
    "from src.utils import play_env, aggregate_list\n",
    "from src.ppo.agent import Agent\n",
    "from src.ppo.config import AgentConfig\n",
    "\n",
    "seed = 1993"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Check the Gym environment\n",
    "\n",
    "Before we start, we need to check how the environment works. For this, we will check the action space and observation space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of actions: 2\n",
      "Sample state shape: (2,)\n",
      "Sample state: [ 1.65625   -0.0546875]\n"
     ]
    }
   ],
   "source": [
    "env = flappy_bird_gym.make(\"FlappyBird-v0\")\n",
    "\n",
    "env.seed(seed)\n",
    "\n",
    "action_size = env.action_space.n\n",
    "state_size = env.observation_space.shape[0]\n",
    "\n",
    "print(f\"Number of actions: {action_size}\")\n",
    "print(f\"Sample state shape: {env.observation_space.shape}\")\n",
    "print(f\"Sample state: {env.reset()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define custom functions\n",
    "\n",
    "In the next cell, we define a `custom_prep_state()` function that can be used to preprocess the state of the game.\n",
    "\n",
    "We will replace the original `prep_state()` (that does nothing) with this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of state: (1, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1.65625   , -0.01171875]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def custom_prep_state(state: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Custom preprocessing of the state.\n",
    "\n",
    "    This function replaces the default preprocessing of the state of the agent (prep_state())\n",
    "\n",
    "    Args:\n",
    "    - state: State to preprocess.\n",
    "\n",
    "    Returns:\n",
    "    - Preprocessed state.\n",
    "    \"\"\"\n",
    "    return state.reshape(1, -1)\n",
    "\n",
    "sample_state = custom_prep_state(env.reset())\n",
    "print(f\"Shape of state: {sample_state.shape}\")\n",
    "sample_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training the RL agent\n",
    "\n",
    "First, we will instantiate the AgentConfig that defines the hyperparameters of our PPO Agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'state_size': 2,\n",
       " 'action_size': 2,\n",
       " 'seed': 1993,\n",
       " 'memory_size': 100000,\n",
       " 'nb_hidden': (64, 64),\n",
       " 'gamma': 0.99,\n",
       " 'lam': 0.97,\n",
       " 'target_kl': 0.01,\n",
       " 'policy_lr': 0.0003,\n",
       " 'value_lr': 0.001,\n",
       " 'train_policy_iters': 10,\n",
       " 'train_value_iters': 10,\n",
       " 'clip_ratio': 0.2,\n",
       " 'epsilon_enabled': True,\n",
       " 'epsilon_start': 1.0,\n",
       " 'epsilon_end': 0.01,\n",
       " 'epsilon_decay': 0.995,\n",
       " 'model_dir': '../models/PPO'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = AgentConfig(\n",
    "    state_size=sample_state.shape[1],\n",
    "    action_size=action_size,\n",
    "    seed=seed,\n",
    "    model_dir=\"../models/PPO\"\n",
    ")\n",
    "\n",
    "params.dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will define the trainer parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_args = {\n",
    "    \"n_episodes\": 60000,\n",
    "    \"print_range\": 1000,\n",
    "    \"early_stop\": 120,\n",
    "    \"verbose\": True,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Agent - Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1000\tAvg Score: 98.79\tEpsilon: 0.01\n",
      "Episode 2000\tAvg Score: 101.32\tEpsilon: 0.01\n",
      "Episode 3000\tAvg Score: 101.00\tEpsilon: 0.01\n",
      "Episode 4000\tAvg Score: 100.68\tEpsilon: 0.01\n",
      "Episode 5000\tAvg Score: 100.69\tEpsilon: 0.01\n",
      "Episode 6000\tAvg Score: 101.00\tEpsilon: 0.01\n",
      "Episode 7000\tAvg Score: 101.00\tEpsilon: 0.01\n",
      "Episode 8000\tAvg Score: 101.00\tEpsilon: 0.01\n",
      "Episode 9000\tAvg Score: 101.00\tEpsilon: 0.01\n",
      "Episode 10000\tAvg Score: 101.01\tEpsilon: 0.01\n",
      "Episode 11000\tAvg Score: 101.03\tEpsilon: 0.01\n",
      "Episode 12000\tAvg Score: 101.01\tEpsilon: 0.01\n",
      "Episode 13000\tAvg Score: 101.07\tEpsilon: 0.01\n",
      "Episode 14000\tAvg Score: 102.96\tEpsilon: 0.01\n",
      "Episode 15000\tAvg Score: 102.08\tEpsilon: 0.01\n",
      "Episode 16000\tAvg Score: 102.39\tEpsilon: 0.01\n",
      "Episode 17000\tAvg Score: 103.74\tEpsilon: 0.01\n",
      "Episode 18000\tAvg Score: 103.05\tEpsilon: 0.01\n",
      "Episode 19000\tAvg Score: 103.26\tEpsilon: 0.01\n",
      "Episode 20000\tAvg Score: 103.01\tEpsilon: 0.01\n",
      "Episode 21000\tAvg Score: 103.65\tEpsilon: 0.01\n",
      "Episode 22000\tAvg Score: 103.75\tEpsilon: 0.01\n",
      "Episode 23000\tAvg Score: 104.09\tEpsilon: 0.01\n",
      "Episode 24000\tAvg Score: 103.84\tEpsilon: 0.01\n",
      "Episode 25000\tAvg Score: 104.58\tEpsilon: 0.01\n",
      "Episode 26000\tAvg Score: 104.08\tEpsilon: 0.01\n",
      "Episode 27000\tAvg Score: 104.72\tEpsilon: 0.01\n",
      "Episode 28000\tAvg Score: 101.52\tEpsilon: 0.01\n",
      "Episode 29000\tAvg Score: 101.14\tEpsilon: 0.01\n",
      "Episode 30000\tAvg Score: 101.00\tEpsilon: 0.01\n",
      "Episode 31000\tAvg Score: 101.00\tEpsilon: 0.01\n",
      "Episode 32000\tAvg Score: 101.01\tEpsilon: 0.01\n",
      "Episode 33000\tAvg Score: 101.01\tEpsilon: 0.01\n",
      "Episode 34000\tAvg Score: 101.87\tEpsilon: 0.01\n",
      "Episode 35000\tAvg Score: 104.62\tEpsilon: 0.01\n",
      "Episode 36000\tAvg Score: 114.10\tEpsilon: 0.01\n",
      "Episode 36029\tAvg Score: 120.53\tEpsilon: 0.01\n",
      "Environment solved in 36029 episodes!\tAvg Score: 120.53\n",
      "Wall time: 1d 6h 5min 53s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "agent = Agent(**params.dict())\n",
    "\n",
    "# Add our custom prep_state function to the agent\n",
    "agent.prep_state = custom_prep_state\n",
    "\n",
    "trainer = Trainer(agent=agent, env=env, **trainer_args)\n",
    "trainer.run(logs_callback=agent.logs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Agent - Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 120.534 - (episode: 36029)\n",
      "Last score: 120.534 - (episode: 36029)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best score: {trainer.best_score} - (episode: {trainer.best_episode})\")\n",
    "print(f\"Last score: {trainer.last_score} - (episode: {trainer.last_episode})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "avg_scores = aggregate_list(trainer.scores, trainer_args[\"print_range\"])\n",
    "x = [i*trainer_args[\"print_range\"] for i in range(len(avg_scores))]\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(x, avg_scores)\n",
    "plt.ylabel(\"Average Score\")\n",
    "plt.xlabel(\"Episode #\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Save agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.save_model(params.model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Load agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "agent = Agent(**params.dict())\n",
    "agent.prep_state = custom_prep_state\n",
    "agent.epsilon_enabled = False\n",
    "\n",
    "agent.load_model(params.model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Test trained agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 840.00\n",
      "Score: 692.00\n",
      "Score: 174.00\n",
      "Score: 527.00\n",
      "Score: 342.00\n",
      "Score: 506.00\n",
      "Score: 770.00\n",
      "Score: 897.00\n",
      "Score: 367.00\n",
      "Score: 1062.00\n"
     ]
    }
   ],
   "source": [
    "env = flappy_bird_gym.make(\"FlappyBird-v0\")\n",
    "env.seed(seed)\n",
    "\n",
    "for i in range(10):\n",
    "    play_env(agent, env, fps=30, render=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Conclusions\n",
    "\n",
    "The Proximal Policy Optimization (PPO) algorithm is a powerful algorithm that can be used to learn playing the Flappy Bird game.\n",
    "\n",
    "We achieved good results with the PPO algorithm after training the agent for 36,000 episodes."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
